Cháº¯c cháº¯n! DÆ°á»›i Ä‘Ã¢y lÃ  phiÃªn báº£n `README.md` **Ä‘Æ°á»£c viáº¿t láº¡i chuyÃªn nghiá»‡p hÆ¡n**, dÃ¹ng vÄƒn phong chuáº©n **repository GitHub táº§m cao**, phÃ¹ há»£p cho cÃ¡ nhÃ¢n, nhÃ³m R\&D, hoáº·c chia sáº» cÃ´ng khai trong cá»™ng Ä‘á»“ng há»c thuáº­t vÃ  cÃ´ng nghiá»‡p.

---

```markdown
<h1 align="center">ğŸ§  YOLOv8 Multi-Object Tracking</h1>
<p align="center">
  Track multiple objects in video streams using YOLOv8 + BoT-SORT with clean batching and visualization pipelines.
</p>

<p align="center">
  <img src="https://img.shields.io/badge/status-production-green" />
  <img src="https://img.shields.io/github/languages/top/your-username/object-tracking-yolo" />
  <img src="https://img.shields.io/github/license/your-username/object-tracking-yolo" />
</p>

---

## ğŸ” Overview

This repository provides a clean, efficient, and scalable pipeline to perform **multi-object tracking** on videos using **Ultralytics YOLOv8** and **BoT-SORT** tracker. It supports:

- âœ… **Batch inference** for speed optimization
- âœ… **Track visualization** with historical motion trails
- âœ… Deployment on both **local machines** and **Google Colab (GPU)**
- âœ… Modularized, production-ready codebase

---

## ğŸ§© Features

- ğŸ¯ YOLOv8 detection with persistent tracking (BoT-SORT)
- ğŸ§µ Batch processing to speed up inference
- ğŸï¸ Track history lines rendered dynamically on video
- ğŸ§¼ Clean, modular Python code with error handling
- ğŸ“¤ Output tracking video in `.mp4` format
- ğŸ§  Easy to use on local machines or Google Colab

---

## ğŸ“‚ Repository Structure
```

object-tracking-yolo/
â”œâ”€â”€ main.py # Entry point for local execution
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ models/ # Pretrained YOLOv8 models (user-supplied)
â”‚ â””â”€â”€ yolo11x.pt
â”œâ”€â”€ samples/ # Sample input videos
â”‚ â””â”€â”€ vietnam.mp4
â”œâ”€â”€ outputs/ # Output tracking videos
â”‚ â””â”€â”€ vietnam_tracked.mp4
â”œâ”€â”€ src/
â”‚ â””â”€â”€ utils.py # Utility functions (e.g., logger)
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ inference_colab.ipynb # Full pipeline runnable on Google Colab

````

---

## ğŸš€ Getting Started

### ğŸ”§ 1. Installation

#### Clone the repository:

```bash
git clone https://github.com/your-username/object-tracking-yolo.git
cd object-tracking-yolo
````

#### \[Optional] Create virtual environment:

```bash
python -m venv venv
source venv/bin/activate        # Linux/macOS
venv\Scripts\activate           # Windows
```

#### Install dependencies:

```bash
pip install -r requirements.txt
```

---

### ğŸ¥ 2. Prepare Inputs

- âœ… Add your input video to the `samples/` folder.
- âœ… Download your YOLOv8 model (e.g. `yolo11x.pt`) and place it in `models/`.

---

### â–¶ï¸ 3. Run Tracking on Local Machine

```bash
python main.py --video-path samples/vietnam.mp4
```

ğŸ“ The output video will be saved in `outputs/` as `vietnam_tracked.mp4`.

---

### ğŸ“’ 4. Run on Google Colab (No Setup Needed)

Use the free GPU of Colab to run tracking directly in the browser:

â–¶ï¸ **[Open `inference_colab.ipynb`](notebooks/inference_colab.ipynb)**

Includes:

- Google Drive integration
- Model + video path configuration
- YOLO tracking with batched processing
- Video output to Drive

---

## âš™ï¸ Configuration

You can change configuration values in `main.py` via:

```python
return {
    "model_path": "models/yolo11x.pt",
    "track_history_length": 120,
    "batch_size": 64,
    "line_thickness": 4,
    "track_color": (230, 230, 230),
}
```

---

## ğŸ“¦ Dependencies

Listed in `requirements.txt`:

```
ultralytics==8.3.162
opencv-python==4.11.0
numpy==2.0.2
tqdm==4.67.1
PyYAML==6.0.2
```

Install via:

```bash
pip install -r requirements.txt
```

---

## ğŸ“Œ Notes

- Default behavior only processes the **first 3 seconds** of video for demo purposes:

  ```python
  frames_to_process = int(fps * 3)
  ```

  âœ Change to `int(cap.get(cv2.CAP_PROP_FRAME_COUNT))` for full video tracking.

- Make sure to check GPU support if running locally with large videos.

---

## ğŸ§  Example Output

> (Optional) Include a `.gif` or `.mp4` demo in `assets/` and embed here:

<p align="center">
  <img src="assets/tracking_preview.gif" width="640"/>
</p>

---

## ğŸ§‘â€ğŸ’» Author

**Khanh Nguyá»…n VÃµ Ngá»c**
AI Research & Computer Vision Developer
ğŸ“« Contact: \[[your.email@example.com](mailto:your.email@example.com)]

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

```

---

### âœ… Æ¯u Ä‘iá»ƒm báº£n README nÃ y:

- Giao diá»‡n Ä‘áº¹p vá»›i emoji, badges
- Ngáº¯n gá»n, chuáº©n bá»‘ cá»¥c GitHub open-source
- CÃ³ hÆ°á»›ng dáº«n cháº¡y trÃªn cáº£ mÃ¡y tháº­t vÃ  Google Colab
- Dá»… copy cho báº¥t ká»³ CV project, AI repo, portfolio nÃ o

---

Báº¡n muá»‘n mÃ¬nh táº¡o sáºµn cáº£ `assets/tracking_preview.gif` tá»« video Ä‘áº§u ra Ä‘á»ƒ Ä‘Æ°a vÃ o README luÃ´n khÃ´ng? Hoáº·c muá»‘n mÃ¬nh táº¡o máº«u `inference_colab.ipynb` chuáº©n hÃ³a Ä‘á»ƒ báº¡n thÃªm vÃ o repo?
```
